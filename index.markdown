---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

# layout: home
layout: page
title: Overview
permalink: /
---
**Date and time: TBD**
**Location: Yokohama, Japan, TBD**

In recent years, deep Reinforcement Learning (RL) has been widely used in various domains includingcomputer games, robotics, vision, and language. For applications in real-world environments, stateof the art reinforcement learning algorithms suffer from a wide range of challenges such as sampleinefficiency,  safety constraints,  partial observability,  dynamic environments,  hidden rewards insystems, and explainability. 

Meanwhile, recent years have seen a blooming in research on supervised learning, where various typesof knowledge are leveraged to help deep neural models to master a task. For instance, knowledgebases (which can either be human labeled or automatically retrieved) are widely used as knowledgesources (in addition to text) in natural language understanding tasks (Ferrucci et al., 2010; Daset al., 2017). Models using pre-trained word embeddings (Mikolov et al., 2013; Pennington et al.,2014; Mikolov et al., 2018) and pre-trained language models (Devlin et al., 2018; Yang et al., 2019)empirically show strong performance on a host of tasks with language components. Similarly, in thevision domain, it is a common practice to initialize a deep neural model by using pre-trained weightmatrices on ImageNet (He et al., 2017).

In addition to incorporating knowledge as an extra input, or into weight matrices, the community hasbeen studying the injection of human understanding of tasks into the structure of neural networksas inductive biases for decades (Rumelhart et al., 1988; Hochreiter and Schmidhuber, 1997; LeCunet al., 2015; Kipf and Welling, 2016). Moreover, knowledge can also be acquired by an agent byexperiencing and interacting with the world on the fly (building and maintaining a memory duringtraining) (Ha and Schmidhuber, 2018).

We believe that incorporating knowledge can potentially solve many of the most pressing challengesfacing reinforcement learning today. The primary goal of this workshop is to facilitate communitybuilding:  we  hope  to  bring  researchers  together  to  consolidate  this  line  of  research  and  fostercollaboration in the community. 

The topics relevant to this workshop will cover a wide variety of methods and problems in the area,including but not limited to:
- Safe Reinforcement Learning;
- Reinforcement Learning for Natural Language Understanding;
- Real-world applications of Reinforcement Learning;
- Relational Reinforcement Learning;
- Model-based Reinforcement Learning;
- Using external knowledge for efficient Reinforcement Learning;
- Transfer Learning for Reinforcement Learning;
- Symbol grounding and Abstractions for Reinforcement Learning;
- Hierarchical Reinforcement Learning;
- Benchmarks for Knowledge guided Reinforcement Learning.


# Diversity and Inclusion

This workshop aims to provide an environment with open exchange of ideas, freedom of thought and expression, and respectful scientific debate.
Thus harassment and hostile behavior (including but not limited to harassment based on race, gender, religion, age, color, appearance, national origin, ancestry, disability, sexual orientation, or gender identity) are unwelcome in the workshop. 
During the workshop, any participant who experiences harassment or hostile behavior may contact any of our organizing committee members, the organizers will take actions upon the situation to make sure we have a diverse, inclusive and friendly environment.

